# -*- coding: utf-8 -*-
"""Basic data preprocessing-liao.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OMgtsqW_w8xMH6TgGhLHFQJp2Vem_kFX
"""

import os, glob
from google.colab import drive
drive.mount('/content/drive')
path = "/content/drive/My Drive/Recommend System"

import pandas as pd
from pandas import DataFrame,Series

os.chdir(path)
os.listdir(path)

data1=pd.read_csv("upcoming_movies.csv")

"""Because the popular movie data set is too large, using** engine='python'**"""

data2= pd.read_csv('top10000_movies.csv', index_col=None, header=0, engine='python')

frames = [data1, data2]
result = pd.concat(frames)

len(result)

result.head()

# result[result['original_language'].str.contains('en')== True] #English movies

"""2512 movies are not English movies"""

# en_result = result[result['original_language'].str.contains('en')== True]

# len(en_result)

print(result.duplicated('id'))

print('Whether there are duplicate observations in the data set: \n',any(result.duplicated()))

result.to_csv('train.csv', columns=['title', 'id', 'overview', 'genre_ids'])

train = pd.read_csv('train.csv')

len(train)

train.dropna(axis=0, how='any', inplace=True)

len(train)

train.duplicated()

print('Whether there are duplicate observations in the data set: \n',any(train.duplicated()))

a = train.drop_duplicates(subset=None, keep='first', inplace=False)

print('Whether there are duplicate observations in the data set: \n',any(a.duplicated()))

a.to_csv('final_movies.csv')

len(a)

(a.isnull()).sum()

DataFrame.drop_duplicates(a, subset=None, keep='first', inplace=False)

b = a.drop_duplicates(subset='id')

len(b)

b.to_csv('final_movies.csv')