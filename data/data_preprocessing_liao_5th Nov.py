# -*- coding: utf-8 -*-
"""Data preprocessing-liao.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OMgtsqW_w8xMH6TgGhLHFQJp2Vem_kFX
"""

import os, glob
from google.colab import drive
drive.mount('/content/drive')
path = "/content/drive/My Drive/Recommend System"

import pandas as pd
from pandas import DataFrame,Series
import json
import csv

os.chdir(path)
os.listdir(path)

data1=pd.read_csv("upcoming_movies.csv")

"""Because the popular movie data set is too large, using** engine= python'"""

data2= pd.read_csv('top10000_movies.csv', index_col=None, header=0, engine='python')

frames = [data1, data2]
result = pd.concat(frames)

len(result)

result.head()

result.info()

# result[result['original_language'].str.contains('en')== True] #English movies, if we do not analysis the title? will be ok???

"""2512 movies are not English movies"""

# en_result = result[result['original_language'].str.contains('en')== True]

print(result.duplicated('id'))

any(result.duplicated('id')) # Duplicate ID was found in this table

result.to_csv('result_1.csv', columns=['title', 'id', 'overview', 'genre_ids'])

result_1 = pd.read_csv('result_1.csv')

result_1.info()

len(result_1)

result_1.dtypes

any(result_1.duplicated('id')) #ID有重复

result_1.isnull().any() #缺失值查询

result_1.isnull().sum() #每一行都存在有缺失值的情况出现

result_2 = result_1.drop_duplicates(subset='id', keep='first', inplace=False) #删掉有重复的ID

len(result_2)

no_missing_result = result_2.dropna()

len(no_missing_result)

no_missing_result.isnull().sum()

no_missing_result.to_csv('no_missing_result.csv')

no_missing_result.info()

genre = no_missing_result['genre_ids']

type(genre)

genre.to_csv('genre.csv')

genre = genre.str.strip('[]')
genre

type(genre)

genre1=genre.to_frame()
genre1

y = pd.DataFrame((x.split(',') for x in genre))
y

no_missing_result=pd.read_csv('no_missing_result.csv')
nmr=no_missing_result[['title', 'id', 'overview', 'genre_ids']]
nmr

df=pd.merge(nmr,y,left_index=True,right_index=True)
dx=nmr.copy()
dx=nmr[0:0]
dx

from tqdm.notebook import tqdm
import numpy as np 
from time import sleep
for i in tqdm(range(len(df))):
    a=df[i:i+1]
    a=a.iloc[:,4:12].dropna(axis=1, how='any')
    a_list =np.array(a).tolist()
    title=df.loc[i,'title']
    id=df.loc[i,'id']
    overview=df.loc[i,'overview']
    for j in a_list[0]:
        dx = dx.append([{'title': title,'id': id,'overview':overview,'genre_ids':j}], ignore_index=True)
dx=dx[-(dx['genre_ids']=='')].reset_index(drop=True)

num_to_label = {
    '28':'Action',
    '12':'Adventure',
    '16':'Animation',
    '35':'Comedy',
    '80':'Crime',
    '99':'Documentary',
    '18':'Drama',
    '10751':'Family',
    '14':'Fantasy',
    '36':'History',
    '27':'Horror',
    '10402':'Music',
    '9648':'Mystery',
    '10749':'Romance',
    '878':'Science Fiction',
    '10770':'TV Movie',
    '53':'Thriller',
    '10752':'War',
    '37':'Western'
    }

dx['genre_ids']=dx.apply(lambda x:(x['genre_ids'].replace(" ", "")), axis=1)
dx['label']=dx.apply(lambda x:(num_to_label[x['genre_ids']]), axis=1)
dx

lab=dx.drop_duplicates(subset=['label'],keep='first',inplace=False)
lab=lab[['label']].reset_index(drop=True)
lab

nr_ids = np.unique(lab)
visGrid = np.zeros((len(nr_ids), len(nr_ids)))
visGrid

for i in range(len(lab)):
    lab.loc[i,'no']=i
movie=dx.drop_duplicates(subset=['id'],keep='first',inplace=False)
movie=movie[['id']].reset_index(drop=True)
for i in tqdm(range(0,len(movie))):
    id=movie.loc[i,'id']
    dxx=dx[dx['id']==id].reset_index(drop=True)
    for j in range(len(dxx)):
        for k in range(len(dxx)):
            labelj=dxx.loc[j,'label']
            laj=lab[lab['label']==dxx.loc[j,'label']].reset_index(drop=True)
            lak=lab[lab['label']==dxx.loc[k,'label']].reset_index(drop=True)
            noj=int(laj.loc[0,'no'])
            nok=int(lak.loc[0,'no'])
            visGrid[noj][nok]=visGrid[noj][nok]+1

import seaborn as sns
annot_lookup = []
for i in range(len(nr_ids)):
    annot_lookup.append(nr_ids[i])
sns.heatmap(visGrid, xticklabels=annot_lookup, yticklabels=annot_lookup)

for i in tqdm(range(len(lab))):
    label=lab.loc[i,'label']
    ds=dx[dx['label']==label]
    lab.loc[i,'count']=len(ds)
lab

import matplotlib.pyplot as plt
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
dis=lab
a = dis['label']
b = dis['count']
plt.barh(a, b)  
plt.title('Movie type frequency')
plt.show()