{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca7c9c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a0a486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('twitter_training.csv',encoding='latin-1',usecols =[\"sentiment\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "067e3920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74048</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74049</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74050</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74051</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74052</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74053 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text\n",
       "0      Positive  im getting on borderlands and i will murder yo...\n",
       "1      Positive  I am coming to the borders and I will kill you...\n",
       "2      Positive  im getting on borderlands and i will kill you ...\n",
       "3      Positive  im coming on borderlands and i will murder you...\n",
       "4      Positive  im getting on borderlands 2 and i will murder ...\n",
       "...         ...                                                ...\n",
       "74048  Positive  Just realized that the Windows partition of my...\n",
       "74049  Positive  Just realized that my Mac window partition is ...\n",
       "74050  Positive  Just realized the windows partition of my Mac ...\n",
       "74051  Positive  Just realized between the windows partition of...\n",
       "74052  Positive  Just like the windows partition of my Mac is l...\n",
       "\n",
       "[74053 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1862ae09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "C = ['sentiment']\n",
    "\n",
    "for i in C:\n",
    "    ch = pd.crosstab(train[i], train['sentiment'])  \n",
    "    ch.plot.bar()   \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "876785c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling = {\n",
    "    'Positive':1, \n",
    "    'Negative':0,\n",
    "    'Neutral':2,\n",
    "    'Irrelevant':3,\n",
    "}\n",
    "\n",
    "train['sentiment'] = train['sentiment'].apply(lambda x : labeling[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad0462df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>So I spent a few hours making something for fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>So I spent a couple of hours doing something f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>So I spent a few hours doing something for fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>So I spent a few hours making something for fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          1  im getting on borderlands and i will murder yo...\n",
       "1          1  I am coming to the borders and I will kill you...\n",
       "2          1  im getting on borderlands and i will kill you ...\n",
       "3          1  im coming on borderlands and i will murder you...\n",
       "4          1  im getting on borderlands 2 and i will murder ...\n",
       "5          1  im getting into borderlands and i can murder y...\n",
       "6          1  So I spent a few hours making something for fu...\n",
       "7          1  So I spent a couple of hours doing something f...\n",
       "8          1  So I spent a few hours doing something for fun...\n",
       "9          1  So I spent a few hours making something for fu..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d5092a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = train.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2fe2740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['im getting on borderlands and i will murder you all ,',\n",
       "       'I am coming to the borders and I will kill you all,',\n",
       "       'im getting on borderlands and i will kill you all,', ...,\n",
       "       'Just realized the windows partition of my Mac is now 6 years behind on Nvidia drivers and I have no idea how he didnâ\\x80\\x99t notice',\n",
       "       'Just realized between the windows partition of my Mac is like being 6 years behind on Nvidia drivers and cars I have no fucking idea how I ever didn â\\x80?t notice',\n",
       "       'Just like the windows partition of my Mac is like 6 years behind on its drivers So you have no idea how I didnâ\\x80\\x99t notice'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55c1e5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    im getting on borderlands and i will murder yo...\n",
       "1    I am coming to the borders and I will kill you...\n",
       "2    im getting on borderlands and i will kill you ...\n",
       "3    im coming on borderlands and i will murder you...\n",
       "4    im getting on borderlands 2 and i will murder ...\n",
       "5    im getting into borderlands and i can murder y...\n",
       "6    So I spent a few hours making something for fu...\n",
       "7    So I spent a couple of hours doing something f...\n",
       "8    So I spent a few hours doing something for fun...\n",
       "9    So I spent a few hours making something for fu...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37764ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba7561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d330509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"[CLS] \" + str(text)+ \" [SEP]\" for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4d6cd0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize the first sentence:\n",
      "['[CLS]', 'im', 'getting', 'on', 'border', '##lands', 'and', 'i', 'will', 'murder', 'you', 'all', ',', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in texts]\n",
    "print (\"Tokenize the first sentence:\")\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f6c3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58258844",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "279e7d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "790e0a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8fbc3ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = train.sentiment.values\n",
    "\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d09eec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "294bf64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 32\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6ebdf8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 407873900/407873900 [01:55<00:00, 3541252.70B/s]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61e77d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2988a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [{'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],'weight_decay_rate': 0.01},\n",
    "                                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],'weight_decay_rate': 0.0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "71a87134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    }
   ],
   "source": [
    "optimizer = BertAdam(optimizer_grouped_parameters,lr=2e-5,warmup=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "609331c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                                     | 0/2 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 2 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-c6636861652d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_input_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mtrain_loss_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# Backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids, attention_mask, labels)\u001b[0m\n\u001b[0;32m    993\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m             \u001b[0mloss_fct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 995\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    996\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m-> 1121\u001b[1;33m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2822\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2824\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 2 is out of bounds."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "\n",
    "t = [] \n",
    "\n",
    "# Store our loss and accuracy for plotting\n",
    "train_loss_set = []\n",
    "\n",
    "# Number of training epochs \n",
    "epochs = 2\n",
    "\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "  \n",
    "  \n",
    "  # Training\n",
    "  \n",
    "  # Set our model to training mode (as opposed to evaluation mode)\n",
    "  model.train()\n",
    "  \n",
    "  # Tracking variables\n",
    "  tr_loss = 0\n",
    "  nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "  # Train the data for one epoch\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    # Add batch to GPU\n",
    "    # batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # Clear out the gradients (by default they accumulate)\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "    train_loss_set.append(loss.item())    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update parameters and take a step using the computed gradient\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    # Update tracking variables\n",
    "    tr_loss += loss.item()\n",
    "    nb_tr_examples += b_input_ids.size(0)\n",
    "    nb_tr_steps += 1\n",
    "\n",
    "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    \n",
    "    \n",
    "  # Validation\n",
    "\n",
    "  # Put model in evaluation mode to evaluate loss on the validation set\n",
    "  model.eval()\n",
    "\n",
    "  # Tracking variables \n",
    "  eval_loss, eval_accuracy = 0, 0\n",
    "  nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "  # Evaluate data for one epoch\n",
    "  for batch in validation_dataloader:\n",
    "    # Add batch to GPU\n",
    "    # batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "    \n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adfc99b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108f6614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
